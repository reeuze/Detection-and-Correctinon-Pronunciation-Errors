{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import difflib\n",
    "\n",
    "from g2p_en import G2p\n",
    "from colorama import Fore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"london the capital city of the united kingdom is a vibrant metropolis rich in history and culture Known as the square mile the city of london is the historic core where the romans first established londinium today it's a major business and financial center housing the Bank of England the royal exchange and the london stock exchange despite its modern skyscrapers like the gherkin and the walkie talkie london retains its historical charm with landmarks such as tower of london the city's boundaries have remained nearly unchanged since medieval times making it a unique blend of ancient and contemporary with a small resident population but a bustling daytime workforce the city is always alive with activity reflecting its status as one of the world's leading financial hubs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = \"E:\\Perkuliahan\\Semester 4\\Pembelajaran Mesin\\Tugas Membuat Makalah\\Speech-to-text\\Data Suara\\Data 8.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to get input from Speech-to-Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_to_text(file_path):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(file_path) as source:\n",
    "        audio_data = recognizer.record(source)\n",
    "        try:\n",
    "            text = recognizer.recognize_google(audio_data, language=\"en-us\", show_all=False)\n",
    "            return text.lower()\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Speech recognition could not understand audio\")\n",
    "            return \"\"\n",
    "        except sr.RequestError as e:\n",
    "            print(\"Error from Google Speech Recognition service\")\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to convert Text to ARPAbet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2p = G2p()\n",
    "def text_to_arpabet(text):\n",
    "    phonemes = g2p(text)\n",
    "    return phonemes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to Compare word based on ARPAbet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_pronunciations(word1, word2):\n",
    "    phonemes1 = text_to_arpabet(word1)\n",
    "    phonemes2 = text_to_arpabet(word2)\n",
    "    return phonemes1 == phonemes2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Error Detection and Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Error_Detection_and_Correction(reference_sentence, user_sentence):\n",
    "    reference_words = reference_sentence.split()\n",
    "    user_words = user_sentence.split()\n",
    "\n",
    "    difference = difflib.ndiff(reference_words, user_words)\n",
    "    matcher = difflib.SequenceMatcher(None, reference_words, user_words)\n",
    "\n",
    "    # Look for the difference between user words and reference words\n",
    "    diff = []\n",
    "    for word in difference:\n",
    "        if word.startswith('- '):\n",
    "            diff.append(f\"Reference missing: {word[2:]}\")\n",
    "        elif word.startswith('+ '):\n",
    "            diff.append(f\"Extra in test: {word[2:]}\")\n",
    "        elif word.startswith('? '):\n",
    "            pass  # This line shows markers for different characters, we can ignore it\n",
    "    \n",
    "    # Calculate Errors\n",
    "    errors = 0\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag != 'equal':\n",
    "            errors += max(i2 - i1, j2 - j1)\n",
    "\n",
    "    # Correct the user sentence\n",
    "    corrected_sentence = []\n",
    "    for tag, i1, i2, j1, j2 in matcher.get_opcodes():\n",
    "        if tag == 'equal':\n",
    "            corrected_sentence.extend(user_words[j1:j2])\n",
    "        elif tag == 'replace':\n",
    "            corrected_sentence.extend(reference_words[i1:i2])\n",
    "        elif tag == 'insert':\n",
    "            corrected_sentence.extend(reference_words[i1:i2])\n",
    "        elif tag == 'delete':\n",
    "            continue\n",
    "\n",
    "    return diff, errors, corrected_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pronunciation_error(provided_sentences, user_sentences):\n",
    "    refernce_words = provided_sentences.split()\n",
    "    user_words = user_sentences.split()\n",
    "    result = []\n",
    "    for reference, user in zip(refernce_words, user_words):\n",
    "        correct = compare_pronunciations(reference, user)\n",
    "        if not correct:\n",
    "            result.append({\n",
    "                'ref' : Fore.WHITE + reference,\n",
    "                'user' : Fore.RED + user,\n",
    "                'Note' : False\n",
    "            })\n",
    "        else:\n",
    "            result.append({\n",
    "                'ref' : Fore.WHITE + reference,\n",
    "                'user' : Fore.GREEN + user,\n",
    "                'Note' : True\n",
    "            })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mlondon <-> \u001b[32mlondon\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37mcapital <-> \u001b[32mcapital\n",
      "\u001b[37mcity <-> \u001b[32mcity\n",
      "\u001b[37mof <-> \u001b[32mof\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37munited <-> \u001b[32munited\n",
      "\u001b[37mkingdom <-> \u001b[32mkingdom\n",
      "\u001b[37mis <-> \u001b[32mis\n",
      "\u001b[37ma <-> \u001b[32ma\n",
      "\u001b[37mvibrant <-> \u001b[31mfire\n",
      "\u001b[37mmetropolis <-> \u001b[31mmetabolic\n",
      "\u001b[37mrich <-> \u001b[31mrate\n",
      "\u001b[37min <-> \u001b[32min\n",
      "\u001b[37mhistory <-> \u001b[32mhistory\n",
      "\u001b[37mand <-> \u001b[32mand\n",
      "\u001b[37mculture <-> \u001b[32mculture\n",
      "\u001b[37mKnown <-> \u001b[31mknow\n",
      "\u001b[37mas <-> \u001b[32mas\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37msquare <-> \u001b[32msquare\n",
      "\u001b[37mmile <-> \u001b[32mmile\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37mcity <-> \u001b[32mcity\n",
      "\u001b[37mof <-> \u001b[32mof\n",
      "\u001b[37mlondon <-> \u001b[32mlondon\n",
      "\u001b[37mis <-> \u001b[32mis\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37mhistoric <-> \u001b[31mhistorical\n",
      "\u001b[37mcore <-> \u001b[31mwhere\n",
      "\u001b[37mwhere <-> \u001b[31mthe\n",
      "\u001b[37mthe <-> \u001b[31mromans\n",
      "\u001b[37mromans <-> \u001b[31mfirst\n",
      "\u001b[37mfirst <-> \u001b[31mestablished\n",
      "\u001b[37mestablished <-> \u001b[31mlondon\n",
      "\u001b[37mlondinium <-> \u001b[31myou\n",
      "\u001b[37mtoday <-> \u001b[32mtoday\n",
      "\u001b[37mit's <-> \u001b[32mit's\n",
      "\u001b[37ma <-> \u001b[32ma\n",
      "\u001b[37mmajor <-> \u001b[32mmajor\n",
      "\u001b[37mbusiness <-> \u001b[32mbusiness\n",
      "\u001b[37mand <-> \u001b[32mand\n",
      "\u001b[37mfinancial <-> \u001b[32mfinancial\n",
      "\u001b[37mcenter <-> \u001b[32mcenter\n",
      "\u001b[37mhousing <-> \u001b[31mhosting\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37mBank <-> \u001b[32mbank\n",
      "\u001b[37mof <-> \u001b[32mof\n",
      "\u001b[37mEngland <-> \u001b[32mengland\n",
      "\u001b[37mthe <-> \u001b[32mthe\n",
      "\u001b[37mroyal <-> \u001b[32mroyal\n",
      "\u001b[37mexchange <-> \u001b[32mexchange\n",
      "\u001b[37mand <-> \u001b[32mand\n",
      "\u001b[37mthe <-> \u001b[31mlondon\n",
      "\u001b[37mlondon <-> \u001b[31mstock\n",
      "\u001b[37mstock <-> \u001b[31mexchange\n",
      "\u001b[37mexchange <-> \u001b[31mdespite\n",
      "\u001b[37mdespite <-> \u001b[31mhis\n",
      "\u001b[37mits <-> \u001b[31mmother\n",
      "\u001b[37mmodern <-> \u001b[31mand\n",
      "\u001b[37mskyscrapers <-> \u001b[31msky\n",
      "\u001b[37mlike <-> \u001b[31mcharacters\n",
      "\u001b[37mthe <-> \u001b[31mlike\n",
      "\u001b[37mgherkin <-> \u001b[31mthe\n",
      "\u001b[37mand <-> \u001b[31mhurricane\n",
      "\u001b[37mthe <-> \u001b[31mand\n",
      "\u001b[37mwalkie <-> \u001b[31mthe\n",
      "\u001b[37mtalkie <-> \u001b[31mwalking\n",
      "\u001b[37mlondon <-> \u001b[31mdistance\n",
      "\u001b[37mretains <-> \u001b[31mfrom\n",
      "\u001b[37mits <-> \u001b[31mtower\n",
      "\u001b[37mhistorical <-> \u001b[31mof\n",
      "\u001b[37mcharm <-> \u001b[31mlondon\n",
      "\u001b[37mwith <-> \u001b[31mthe\n",
      "\u001b[37mlandmarks <-> \u001b[31mcity\n",
      "\u001b[37msuch <-> \u001b[31mmissouri\n",
      "\u001b[37mas <-> \u001b[31mweather\n"
     ]
    }
   ],
   "source": [
    "user_words = get_speech_to_text(audio_file)\n",
    "results = detect_pronunciation_error(sentence, user_words)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"{result['ref']} <-> {result['user']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37mWrong Words : \u001b[32mlondon \u001b[32mthe \u001b[32mcapital \u001b[32mcity \u001b[32mof \u001b[32mthe \u001b[32munited \u001b[32mkingdom \u001b[32mis \u001b[32ma \u001b[31mfire \u001b[31mmetabolic \u001b[31mrate \u001b[32min \u001b[32mhistory \u001b[32mand \u001b[32mculture \u001b[31mknow \u001b[32mas \u001b[32mthe \u001b[32msquare \u001b[32mmile \u001b[32mthe \u001b[32mcity \u001b[32mof \u001b[32mlondon \u001b[32mis \u001b[32mthe \u001b[31mhistorical \u001b[31mwhere \u001b[31mthe \u001b[31mromans \u001b[31mfirst \u001b[31mestablished \u001b[31mlondon \u001b[31myou \u001b[32mtoday \u001b[32mit's \u001b[32ma \u001b[32mmajor \u001b[32mbusiness \u001b[32mand \u001b[32mfinancial \u001b[32mcenter \u001b[31mhosting \u001b[32mthe \u001b[32mbank \u001b[32mof \u001b[32mengland \u001b[32mthe \u001b[32mroyal \u001b[32mexchange \u001b[32mand \u001b[31mlondon \u001b[31mstock \u001b[31mexchange \u001b[31mdespite \u001b[31mhis \u001b[31mmother \u001b[31mand \u001b[31msky \u001b[31mcharacters \u001b[31mlike \u001b[31mthe \u001b[31mhurricane \u001b[31mand \u001b[31mthe \u001b[31mwalking \u001b[31mdistance \u001b[31mfrom \u001b[31mtower \u001b[31mof \u001b[31mlondon \u001b[31mthe \u001b[31mcity \u001b[31mmissouri \u001b[31mweather\n",
      "\u001b[37mCorrect Words : \u001b[32mlondon \u001b[32mthe \u001b[32mcapital \u001b[32mcity \u001b[32mof \u001b[32mthe \u001b[32munited \u001b[32mkingdom \u001b[32mis \u001b[32ma \u001b[37mvibrant \u001b[37mmetropolis \u001b[37mrich \u001b[32min \u001b[32mhistory \u001b[32mand \u001b[32mculture \u001b[37mKnown \u001b[32mas \u001b[32mthe \u001b[32msquare \u001b[32mmile \u001b[32mthe \u001b[32mcity \u001b[32mof \u001b[32mlondon \u001b[32mis \u001b[32mthe \u001b[37mhistoric \u001b[37mcore \u001b[37mwhere \u001b[37mthe \u001b[37mromans \u001b[37mfirst \u001b[37mestablished \u001b[37mlondinium \u001b[32mtoday \u001b[32mit's \u001b[32ma \u001b[32mmajor \u001b[32mbusiness \u001b[32mand \u001b[32mfinancial \u001b[32mcenter \u001b[37mhousing \u001b[32mthe \u001b[32mbank \u001b[32mof \u001b[32mengland \u001b[32mthe \u001b[32mroyal \u001b[32mexchange \u001b[32mand \u001b[37mthe \u001b[37mlondon \u001b[37mstock \u001b[37mexchange \u001b[37mdespite \u001b[37mits \u001b[37mmodern \u001b[37mskyscrapers \u001b[37mlike \u001b[37mthe \u001b[37mgherkin \u001b[37mand \u001b[37mthe \u001b[37mwalkie \u001b[37mtalkie \u001b[37mlondon \u001b[37mretains \u001b[37mits \u001b[37mhistorical \u001b[37mcharm \u001b[37mwith \u001b[37mlandmarks \u001b[37msuch \u001b[37mas\n",
      "\n",
      "Error Precentage from detection : 48.05194805194805 %\n"
     ]
    }
   ],
   "source": [
    "Correct_words = []\n",
    "Wrong_words = []\n",
    "Error = 0\n",
    "for result in results:\n",
    "    Wrong_words.append(result['user'])\n",
    "    if (result['Note'] == False):\n",
    "        Correct_words.append(result['ref'])\n",
    "        Error += 1\n",
    "    else:\n",
    "        Correct_words.append(result['user'])\n",
    "print(Fore.WHITE + \"Wrong Words : \" + ' '.join(Wrong_words))\n",
    "print(Fore.WHITE + \"Correct Words : \" + ' '.join(Correct_words) + '\\n')\n",
    "print(f\"Error Precentage from detection : {(Error/len(Correct_words)*100)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Detection and Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference missing: vibrant\n",
      "Reference missing: metropolis\n",
      "Reference missing: rich\n",
      "Extra in test: fire\n",
      "Extra in test: metabolic\n",
      "Extra in test: rate\n",
      "Reference missing: Known\n",
      "Extra in test: know\n",
      "Reference missing: historic\n",
      "Extra in test: historical\n",
      "Reference missing: core\n",
      "Reference missing: londinium\n",
      "Extra in test: london\n",
      "Extra in test: you\n",
      "Reference missing: housing\n",
      "Extra in test: hosting\n",
      "Reference missing: Bank\n",
      "Extra in test: bank\n",
      "Reference missing: England\n",
      "Extra in test: england\n",
      "Reference missing: the\n",
      "Reference missing: its\n",
      "Reference missing: modern\n",
      "Reference missing: skyscrapers\n",
      "Extra in test: his\n",
      "Extra in test: mother\n",
      "Extra in test: and\n",
      "Extra in test: sky\n",
      "Extra in test: characters\n",
      "Reference missing: gherkin\n",
      "Extra in test: hurricane\n",
      "Reference missing: walkie\n",
      "Extra in test: walking\n",
      "Extra in test: distance\n",
      "Extra in test: from\n",
      "Reference missing: talkie\n",
      "Reference missing: london\n",
      "Reference missing: retains\n",
      "Reference missing: its\n",
      "Reference missing: historical\n",
      "Reference missing: charm\n",
      "Reference missing: with\n",
      "Reference missing: landmarks\n",
      "Reference missing: such\n",
      "Reference missing: as\n",
      "Reference missing: city's\n",
      "Reference missing: boundaries\n",
      "Reference missing: have\n",
      "Reference missing: remained\n",
      "Reference missing: nearly\n",
      "Reference missing: unchanged\n",
      "Reference missing: since\n",
      "Reference missing: medieval\n",
      "Reference missing: times\n",
      "Reference missing: making\n",
      "Reference missing: it\n",
      "Reference missing: a\n",
      "Reference missing: unique\n",
      "Reference missing: blend\n",
      "Reference missing: of\n",
      "Reference missing: ancient\n",
      "Reference missing: and\n",
      "Reference missing: contemporary\n",
      "Reference missing: with\n",
      "Reference missing: a\n",
      "Reference missing: small\n",
      "Reference missing: resident\n",
      "Reference missing: population\n",
      "Reference missing: but\n",
      "Reference missing: a\n",
      "Reference missing: bustling\n",
      "Reference missing: daytime\n",
      "Reference missing: workforce\n",
      "Reference missing: the\n",
      "Extra in test: missouri\n",
      "Extra in test: weather\n",
      "Reference missing: is\n",
      "Reference missing: always\n",
      "Reference missing: alive\n",
      "Reference missing: with\n",
      "Reference missing: activity\n",
      "Reference missing: reflecting\n",
      "Reference missing: its\n",
      "Reference missing: status\n",
      "Reference missing: as\n",
      "Reference missing: one\n",
      "Reference missing: of\n",
      "Reference missing: the\n",
      "Reference missing: world's\n",
      "Reference missing: leading\n",
      "Reference missing: financial\n",
      "Reference missing: hubs.\n",
      "\n",
      "\n",
      "Number of errors: 58.26771653543307 %\n",
      "Corrected sentence: ['london', 'the', 'capital', 'city', 'of', 'the', 'united', 'kingdom', 'is', 'a', 'vibrant', 'metropolis', 'rich', 'in', 'history', 'and', 'culture', 'Known', 'as', 'the', 'square', 'mile', 'the', 'city', 'of', 'london', 'is', 'the', 'historic', 'core', 'where', 'the', 'romans', 'first', 'established', 'londinium', 'today', \"it's\", 'a', 'major', 'business', 'and', 'financial', 'center', 'housing', 'the', 'Bank', 'of', 'England', 'the', 'royal', 'exchange', 'and', 'london', 'stock', 'exchange', 'despite', 'its', 'modern', 'skyscrapers', 'like', 'the', 'gherkin', 'and', 'the', 'walkie', 'talkie', 'london', 'retains', 'its', 'historical', 'charm', 'with', 'landmarks', 'such', 'as', 'tower', 'of', 'london', 'the', 'city', 'is', 'always', 'alive', 'with', 'activity', 'reflecting', 'its', 'status', 'as', 'one', 'of', 'the', \"world's\", 'leading', 'financial', 'hubs.']\n"
     ]
    }
   ],
   "source": [
    "user_words = get_speech_to_text(audio_file)\n",
    "Error_words, error, corrected_sentence = Error_Detection_and_Correction(sentence, user_words)\n",
    "\n",
    "for word in Error_words:\n",
    "    print(word)\n",
    "print('\\n')\n",
    "print(f\"Number of errors: {(error/len(sentence.split()))*100} %\")\n",
    "print(\"Corrected sentence:\", corrected_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
